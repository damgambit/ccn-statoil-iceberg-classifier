{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "np.random.seed(666)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "train = pd.read_json(\"train.json\")\n",
    "test = pd.read_json(\"test.json\")\n",
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_train = np.array(train.inc_angle)\n",
    "y_train = np.array(train[\"is_iceberg\"])\n",
    "\n",
    "# Test data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_test = np.array(test.inc_angle)\n",
    "\n",
    "\n",
    "X_train, X_valid, X_angle_train, X_angle_valid, y_train, y_valid = train_test_split(X_train\n",
    "                    , X_angle_train, y_train, random_state=123, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (7, 7), activation=\"elu\", input_shape=(75, 75, 3...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (7, 7), activation=\"elu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"elu\")`\n",
      "  \"\"\"\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  app.launch_new_instance()\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, 7, 7, input_shape=(75, 75, 3), activation='elu'))\n",
    "model.add(Conv2D(32, 7, 7, activation='elu'))\n",
    "model.add(Conv2D(32, 3, 3, activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "model.add(Conv2D(128, 3, 3, activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(128, 3, 3, activation='elu'))\n",
    "model.add(Conv2D(128, 3, 3, activation='elu'))\n",
    "model.add(Conv2D(128, 3, 3, activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(128, 3, 3, activation='elu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', optimizer=keras.optimizers.adam(lr=0.00003, decay=0.005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1203/1203 [==============================] - 2s - loss: 0.5053 - acc: 0.4896     \n",
      "Epoch 2/400\n",
      " 128/1203 [==>...........................] - ETA: 1s - loss: 0.4747 - acc: 0.5469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/keras/callbacks.py:496: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: acc,loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/home/ramdoot/anaconda2/lib/python2.7/site-packages/keras/callbacks.py:405: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203/1203 [==============================] - 1s - loss: 0.4692 - acc: 0.5461     \n",
      "Epoch 3/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4628 - acc: 0.5470     \n",
      "Epoch 4/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4555 - acc: 0.5536     \n",
      "Epoch 5/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4563 - acc: 0.5453     \n",
      "Epoch 6/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4550 - acc: 0.5478     \n",
      "Epoch 7/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4540 - acc: 0.5470     \n",
      "Epoch 8/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4538 - acc: 0.5470     \n",
      "Epoch 9/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4528 - acc: 0.5453     \n",
      "Epoch 10/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4434 - acc: 0.5586     \n",
      "Epoch 11/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4277 - acc: 0.6043     \n",
      "Epoch 12/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.4166 - acc: 0.5960     \n",
      "Epoch 13/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.3844 - acc: 0.6509     \n",
      "Epoch 14/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.3594 - acc: 0.6725     \n",
      "Epoch 15/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.3357 - acc: 0.6974     \n",
      "Epoch 16/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.3448 - acc: 0.6633     \n",
      "Epoch 17/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.3110 - acc: 0.7182     \n",
      "Epoch 18/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.3050 - acc: 0.7190     \n",
      "Epoch 19/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2890 - acc: 0.7415     \n",
      "Epoch 20/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2724 - acc: 0.7556     \n",
      "Epoch 21/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2656 - acc: 0.7639     \n",
      "Epoch 22/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2615 - acc: 0.7623     \n",
      "Epoch 23/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2518 - acc: 0.7722     \n",
      "Epoch 24/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2448 - acc: 0.7872     \n",
      "Epoch 25/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2364 - acc: 0.7980     \n",
      "Epoch 26/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2334 - acc: 0.7880     \n",
      "Epoch 27/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2277 - acc: 0.7947     \n",
      "Epoch 28/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2155 - acc: 0.8188     \n",
      "Epoch 29/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2100 - acc: 0.8246     \n",
      "Epoch 30/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2093 - acc: 0.8221     \n",
      "Epoch 31/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.2001 - acc: 0.8387     \n",
      "Epoch 32/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1998 - acc: 0.8346     \n",
      "Epoch 33/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1948 - acc: 0.8421     \n",
      "Epoch 34/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1873 - acc: 0.8529     \n",
      "Epoch 35/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1901 - acc: 0.8387     \n",
      "Epoch 36/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1854 - acc: 0.8454     \n",
      "Epoch 37/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1783 - acc: 0.8612     \n",
      "Epoch 38/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1763 - acc: 0.8537     \n",
      "Epoch 39/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1744 - acc: 0.8495     \n",
      "Epoch 40/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1790 - acc: 0.8495     \n",
      "Epoch 41/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1781 - acc: 0.8529     \n",
      "Epoch 42/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1678 - acc: 0.8462     \n",
      "Epoch 43/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1623 - acc: 0.8645     \n",
      "Epoch 44/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1675 - acc: 0.8570     \n",
      "Epoch 45/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1586 - acc: 0.8670     \n",
      "Epoch 46/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1576 - acc: 0.8720     \n",
      "Epoch 47/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1627 - acc: 0.8579     \n",
      "Epoch 48/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1552 - acc: 0.8728     \n",
      "Epoch 49/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1645 - acc: 0.8612     \n",
      "Epoch 50/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1562 - acc: 0.8628     \n",
      "Epoch 51/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1523 - acc: 0.8745     \n",
      "Epoch 52/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1508 - acc: 0.8728     \n",
      "Epoch 53/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1543 - acc: 0.8653     \n",
      "Epoch 54/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1494 - acc: 0.8786     \n",
      "Epoch 55/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1465 - acc: 0.8753     \n",
      "Epoch 56/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1480 - acc: 0.8753     \n",
      "Epoch 57/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1449 - acc: 0.8761     \n",
      "Epoch 58/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1499 - acc: 0.8687     \n",
      "Epoch 59/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1453 - acc: 0.8745     \n",
      "Epoch 60/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1438 - acc: 0.8770     \n",
      "Epoch 61/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1418 - acc: 0.8811     \n",
      "Epoch 62/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1447 - acc: 0.8753     \n",
      "Epoch 63/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1433 - acc: 0.8786     \n",
      "Epoch 64/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1413 - acc: 0.8820     \n",
      "Epoch 65/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1410 - acc: 0.8820     \n",
      "Epoch 66/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1392 - acc: 0.8820     \n",
      "Epoch 67/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1408 - acc: 0.8820     \n",
      "Epoch 68/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1348 - acc: 0.8894     \n",
      "Epoch 69/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1404 - acc: 0.8820     \n",
      "Epoch 70/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1341 - acc: 0.8861     \n",
      "Epoch 71/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1376 - acc: 0.8828     \n",
      "Epoch 72/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1344 - acc: 0.8853     \n",
      "Epoch 73/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1341 - acc: 0.8861     \n",
      "Epoch 74/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1360 - acc: 0.8845     \n",
      "Epoch 75/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1342 - acc: 0.8845     \n",
      "Epoch 76/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1332 - acc: 0.8903     \n",
      "Epoch 77/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1288 - acc: 0.8911     \n",
      "Epoch 78/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1332 - acc: 0.8828     \n",
      "Epoch 79/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1305 - acc: 0.8911     \n",
      "Epoch 80/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1309 - acc: 0.8853     \n",
      "Epoch 81/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1302 - acc: 0.8903     \n",
      "Epoch 82/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1304 - acc: 0.8911     \n",
      "Epoch 83/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1295 - acc: 0.8869     \n",
      "Epoch 84/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1271 - acc: 0.8911     \n",
      "Epoch 85/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1269 - acc: 0.8919     \n",
      "Epoch 86/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1253 - acc: 0.8953     \n",
      "Epoch 87/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1296 - acc: 0.8853     \n",
      "Epoch 88/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203/1203 [==============================] - 1s - loss: 0.1286 - acc: 0.8894     \n",
      "Epoch 89/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1235 - acc: 0.8919     \n",
      "Epoch 90/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1287 - acc: 0.8936     \n",
      "Epoch 91/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1278 - acc: 0.8886     \n",
      "Epoch 92/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1256 - acc: 0.8894     \n",
      "Epoch 93/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1246 - acc: 0.8919     \n",
      "Epoch 94/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1247 - acc: 0.8928     \n",
      "Epoch 95/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1233 - acc: 0.8994     \n",
      "Epoch 96/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1249 - acc: 0.8944     \n",
      "Epoch 97/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1196 - acc: 0.9011     \n",
      "Epoch 98/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1221 - acc: 0.8953     \n",
      "Epoch 99/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1218 - acc: 0.8978     \n",
      "Epoch 100/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1182 - acc: 0.8978     \n",
      "Epoch 101/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1199 - acc: 0.8978     \n",
      "Epoch 102/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1191 - acc: 0.9002     \n",
      "Epoch 103/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1197 - acc: 0.8986     \n",
      "Epoch 104/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1168 - acc: 0.9044     \n",
      "Epoch 105/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1211 - acc: 0.8928     \n",
      "Epoch 106/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1188 - acc: 0.9002     \n",
      "Epoch 107/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1170 - acc: 0.8978     \n",
      "Epoch 108/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1174 - acc: 0.8986     \n",
      "Epoch 109/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1161 - acc: 0.9011     \n",
      "Epoch 110/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1137 - acc: 0.9044     \n",
      "Epoch 111/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1132 - acc: 0.9086     \n",
      "Epoch 112/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1161 - acc: 0.8994     \n",
      "Epoch 113/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1163 - acc: 0.9044     \n",
      "Epoch 114/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1152 - acc: 0.8994     \n",
      "Epoch 115/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1155 - acc: 0.9011     \n",
      "Epoch 116/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1157 - acc: 0.9027     \n",
      "Epoch 117/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1154 - acc: 0.8953     \n",
      "Epoch 118/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1180 - acc: 0.8986     \n",
      "Epoch 119/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1158 - acc: 0.8986     \n",
      "Epoch 120/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1100 - acc: 0.9111     \n",
      "Epoch 121/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1129 - acc: 0.9052     \n",
      "Epoch 122/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1139 - acc: 0.9052     \n",
      "Epoch 123/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1151 - acc: 0.8994     \n",
      "Epoch 124/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1143 - acc: 0.9019     \n",
      "Epoch 125/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1115 - acc: 0.9061     \n",
      "Epoch 126/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1118 - acc: 0.9052     \n",
      "Epoch 127/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1109 - acc: 0.9036     \n",
      "Epoch 128/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1112 - acc: 0.9077     \n",
      "Epoch 129/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1139 - acc: 0.8994     \n",
      "Epoch 130/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1102 - acc: 0.9061     \n",
      "Epoch 131/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1088 - acc: 0.9111     \n",
      "Epoch 132/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1112 - acc: 0.9019     \n",
      "Epoch 133/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1124 - acc: 0.9011     \n",
      "Epoch 134/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1102 - acc: 0.9019     \n",
      "Epoch 135/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1106 - acc: 0.9044     \n",
      "Epoch 136/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1082 - acc: 0.9119     \n",
      "Epoch 137/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1095 - acc: 0.9061     \n",
      "Epoch 138/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1062 - acc: 0.9119     \n",
      "Epoch 139/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1065 - acc: 0.9094     \n",
      "Epoch 140/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1088 - acc: 0.9036     \n",
      "Epoch 141/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1107 - acc: 0.9036     \n",
      "Epoch 142/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1125 - acc: 0.9011     \n",
      "Epoch 143/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1065 - acc: 0.9102     \n",
      "Epoch 144/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1082 - acc: 0.9111     \n",
      "Epoch 145/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1061 - acc: 0.9111     \n",
      "Epoch 146/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1061 - acc: 0.9111     \n",
      "Epoch 147/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1079 - acc: 0.9011     \n",
      "Epoch 148/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1092 - acc: 0.9061     \n",
      "Epoch 149/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1076 - acc: 0.9061     \n",
      "Epoch 150/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1076 - acc: 0.9094     \n",
      "Epoch 151/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1075 - acc: 0.9077     \n",
      "Epoch 152/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1046 - acc: 0.9094     \n",
      "Epoch 153/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1060 - acc: 0.9144     \n",
      "Epoch 154/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1012 - acc: 0.9135     \n",
      "Epoch 155/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1053 - acc: 0.9061     \n",
      "Epoch 156/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1108 - acc: 0.9069     \n",
      "Epoch 157/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1044 - acc: 0.9077     \n",
      "Epoch 158/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1028 - acc: 0.9144     \n",
      "Epoch 159/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1036 - acc: 0.9135     \n",
      "Epoch 160/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0995 - acc: 0.9194     \n",
      "Epoch 161/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1010 - acc: 0.9144     \n",
      "Epoch 162/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1001 - acc: 0.9177     \n",
      "Epoch 163/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1028 - acc: 0.9135     \n",
      "Epoch 164/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1035 - acc: 0.9086     \n",
      "Epoch 165/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1015 - acc: 0.9160     \n",
      "Epoch 166/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1010 - acc: 0.9152     \n",
      "Epoch 167/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1032 - acc: 0.9160     \n",
      "Epoch 168/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0997 - acc: 0.9202     \n",
      "Epoch 169/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1011 - acc: 0.9119     \n",
      "Epoch 170/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0996 - acc: 0.9169     \n",
      "Epoch 171/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1032 - acc: 0.9102     \n",
      "Epoch 172/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1012 - acc: 0.9202     \n",
      "Epoch 173/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203/1203 [==============================] - 1s - loss: 0.1025 - acc: 0.9111     \n",
      "Epoch 174/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1058 - acc: 0.9127     \n",
      "Epoch 175/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1005 - acc: 0.9127     \n",
      "Epoch 176/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0998 - acc: 0.9169     \n",
      "Epoch 177/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0988 - acc: 0.9144     \n",
      "Epoch 178/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1005 - acc: 0.9169     \n",
      "Epoch 179/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0999 - acc: 0.9185     \n",
      "Epoch 180/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0989 - acc: 0.9160     \n",
      "Epoch 181/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1006 - acc: 0.9144     \n",
      "Epoch 182/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0995 - acc: 0.9185     \n",
      "Epoch 183/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1002 - acc: 0.9185     \n",
      "Epoch 184/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0997 - acc: 0.9194     \n",
      "Epoch 185/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0975 - acc: 0.9185     \n",
      "Epoch 186/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0967 - acc: 0.9194     \n",
      "Epoch 187/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0979 - acc: 0.9210     \n",
      "Epoch 188/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0992 - acc: 0.9119     \n",
      "Epoch 189/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0986 - acc: 0.9169     \n",
      "Epoch 190/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0998 - acc: 0.9169     \n",
      "Epoch 191/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1011 - acc: 0.9094     \n",
      "Epoch 192/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0985 - acc: 0.9135     \n",
      "Epoch 193/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0945 - acc: 0.9185     \n",
      "Epoch 194/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0950 - acc: 0.9210     \n",
      "Epoch 195/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.1003 - acc: 0.9127     \n",
      "Epoch 196/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0935 - acc: 0.9177     \n",
      "Epoch 197/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0957 - acc: 0.9194     \n",
      "Epoch 198/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0955 - acc: 0.9202     \n",
      "Epoch 199/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0964 - acc: 0.9185     \n",
      "Epoch 200/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0961 - acc: 0.9185     \n",
      "Epoch 201/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0971 - acc: 0.9185     \n",
      "Epoch 202/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0970 - acc: 0.9185     \n",
      "Epoch 203/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0965 - acc: 0.9185     \n",
      "Epoch 204/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0938 - acc: 0.9210     \n",
      "Epoch 205/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0934 - acc: 0.9244     \n",
      "Epoch 206/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0976 - acc: 0.9185     \n",
      "Epoch 207/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0937 - acc: 0.9227     \n",
      "Epoch 208/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0911 - acc: 0.9235     \n",
      "Epoch 209/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0943 - acc: 0.9210     \n",
      "Epoch 210/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0945 - acc: 0.9235     \n",
      "Epoch 211/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0941 - acc: 0.9202     \n",
      "Epoch 212/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0932 - acc: 0.9194     \n",
      "Epoch 213/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0937 - acc: 0.9235     \n",
      "Epoch 214/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0918 - acc: 0.9252     \n",
      "Epoch 215/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0921 - acc: 0.9177     \n",
      "Epoch 216/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0943 - acc: 0.9227     \n",
      "Epoch 217/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0961 - acc: 0.9169     \n",
      "Epoch 218/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0945 - acc: 0.9227     \n",
      "Epoch 219/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0937 - acc: 0.9235     \n",
      "Epoch 220/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0921 - acc: 0.9252     \n",
      "Epoch 221/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0935 - acc: 0.9185     \n",
      "Epoch 222/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0927 - acc: 0.9219     \n",
      "Epoch 223/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0929 - acc: 0.9210     \n",
      "Epoch 224/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0925 - acc: 0.9185     \n",
      "Epoch 225/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0903 - acc: 0.9268     \n",
      "Epoch 226/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0938 - acc: 0.9210     \n",
      "Epoch 227/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0938 - acc: 0.9202     \n",
      "Epoch 228/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0909 - acc: 0.9268     \n",
      "Epoch 229/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0879 - acc: 0.9277     \n",
      "Epoch 230/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0914 - acc: 0.9260     \n",
      "Epoch 231/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0912 - acc: 0.9244     \n",
      "Epoch 232/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0901 - acc: 0.9210     \n",
      "Epoch 233/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0927 - acc: 0.9260     \n",
      "Epoch 234/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0902 - acc: 0.9235     \n",
      "Epoch 235/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0895 - acc: 0.9268     \n",
      "Epoch 236/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0879 - acc: 0.9268     \n",
      "Epoch 237/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0913 - acc: 0.9260     \n",
      "Epoch 238/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0939 - acc: 0.9202     \n",
      "Epoch 239/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0887 - acc: 0.9268     \n",
      "Epoch 240/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0901 - acc: 0.9210     \n",
      "Epoch 241/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0878 - acc: 0.9252     \n",
      "Epoch 242/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0883 - acc: 0.9268     \n",
      "Epoch 243/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0940 - acc: 0.9210     \n",
      "Epoch 244/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0882 - acc: 0.9252     \n",
      "Epoch 245/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0902 - acc: 0.9227     \n",
      "Epoch 246/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0915 - acc: 0.9185     \n",
      "Epoch 247/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0880 - acc: 0.9244     \n",
      "Epoch 248/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0914 - acc: 0.9210     \n",
      "Epoch 249/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0883 - acc: 0.9244     \n",
      "Epoch 250/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0897 - acc: 0.9210     \n",
      "Epoch 251/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0868 - acc: 0.9268     \n",
      "Epoch 252/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0896 - acc: 0.9235     \n",
      "Epoch 253/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0876 - acc: 0.9277     \n",
      "Epoch 254/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0880 - acc: 0.9244     \n",
      "Epoch 255/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0877 - acc: 0.9260     \n",
      "Epoch 256/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0879 - acc: 0.9235     \n",
      "Epoch 257/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0899 - acc: 0.9293     \n",
      "Epoch 258/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203/1203 [==============================] - 1s - loss: 0.0876 - acc: 0.9260     \n",
      "Epoch 259/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0868 - acc: 0.9252     \n",
      "Epoch 260/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0885 - acc: 0.9260     \n",
      "Epoch 261/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0851 - acc: 0.9244     \n",
      "Epoch 262/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0890 - acc: 0.9252     \n",
      "Epoch 263/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0882 - acc: 0.9235     \n",
      "Epoch 264/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0867 - acc: 0.9235     \n",
      "Epoch 265/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0877 - acc: 0.9252     \n",
      "Epoch 266/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0875 - acc: 0.9310     \n",
      "Epoch 267/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0873 - acc: 0.9252     \n",
      "Epoch 268/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0868 - acc: 0.9244     \n",
      "Epoch 269/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0855 - acc: 0.9268     \n",
      "Epoch 270/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0851 - acc: 0.9277     \n",
      "Epoch 271/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0849 - acc: 0.9277     \n",
      "Epoch 272/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0851 - acc: 0.9293     \n",
      "Epoch 273/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0861 - acc: 0.9302     \n",
      "Epoch 274/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0852 - acc: 0.9277     \n",
      "Epoch 275/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0879 - acc: 0.9244     \n",
      "Epoch 276/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0860 - acc: 0.9293     \n",
      "Epoch 277/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0850 - acc: 0.9302     \n",
      "Epoch 278/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0851 - acc: 0.9327     \n",
      "Epoch 279/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0837 - acc: 0.9277     \n",
      "Epoch 280/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0869 - acc: 0.9302     \n",
      "Epoch 281/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0871 - acc: 0.9293     \n",
      "Epoch 282/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0851 - acc: 0.9252     \n",
      "Epoch 283/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0866 - acc: 0.9318     \n",
      "Epoch 284/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0827 - acc: 0.9310     \n",
      "Epoch 285/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0849 - acc: 0.9268     \n",
      "Epoch 286/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0829 - acc: 0.9318     \n",
      "Epoch 287/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0868 - acc: 0.9293     \n",
      "Epoch 288/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0825 - acc: 0.9277     \n",
      "Epoch 289/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0838 - acc: 0.9310     \n",
      "Epoch 290/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0841 - acc: 0.9327     \n",
      "Epoch 291/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0849 - acc: 0.9293     \n",
      "Epoch 292/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0844 - acc: 0.9293     \n",
      "Epoch 293/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0848 - acc: 0.9268     \n",
      "Epoch 294/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0826 - acc: 0.9318     \n",
      "Epoch 295/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0846 - acc: 0.9285     \n",
      "Epoch 296/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0870 - acc: 0.9268     \n",
      "Epoch 297/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0847 - acc: 0.9310     \n",
      "Epoch 298/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0839 - acc: 0.9260     \n",
      "Epoch 299/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0836 - acc: 0.9318     \n",
      "Epoch 300/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0834 - acc: 0.9310     \n",
      "Epoch 301/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0843 - acc: 0.9268     \n",
      "Epoch 302/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0822 - acc: 0.9293     \n",
      "Epoch 303/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0824 - acc: 0.9310     \n",
      "Epoch 304/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0816 - acc: 0.9302     \n",
      "Epoch 305/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0826 - acc: 0.9318     \n",
      "Epoch 306/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0845 - acc: 0.9252     \n",
      "Epoch 307/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0839 - acc: 0.9260     \n",
      "Epoch 308/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0850 - acc: 0.9235     \n",
      "Epoch 309/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0825 - acc: 0.9327     \n",
      "Epoch 310/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0811 - acc: 0.9310     \n",
      "Epoch 311/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0811 - acc: 0.9343     \n",
      "Epoch 312/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0815 - acc: 0.9327     \n",
      "Epoch 313/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0826 - acc: 0.9310     \n",
      "Epoch 314/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0813 - acc: 0.9327     \n",
      "Epoch 315/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0820 - acc: 0.9335     \n",
      "Epoch 316/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0823 - acc: 0.9310     \n",
      "Epoch 317/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0815 - acc: 0.9327     \n",
      "Epoch 318/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0831 - acc: 0.9310     \n",
      "Epoch 319/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0803 - acc: 0.9343     \n",
      "Epoch 320/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0836 - acc: 0.9310     \n",
      "Epoch 321/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0799 - acc: 0.9335     \n",
      "Epoch 322/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0787 - acc: 0.9360     \n",
      "Epoch 323/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0799 - acc: 0.9318     \n",
      "Epoch 324/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0803 - acc: 0.9318     \n",
      "Epoch 325/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0795 - acc: 0.9335     \n",
      "Epoch 326/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0784 - acc: 0.9360     \n",
      "Epoch 327/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0819 - acc: 0.9335     \n",
      "Epoch 328/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0807 - acc: 0.9335     \n",
      "Epoch 329/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0801 - acc: 0.9327     \n",
      "Epoch 330/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0790 - acc: 0.9343     \n",
      "Epoch 331/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0815 - acc: 0.9352     \n",
      "Epoch 332/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0814 - acc: 0.9310     \n",
      "Epoch 333/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0778 - acc: 0.9360     \n",
      "Epoch 334/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0839 - acc: 0.9277     \n",
      "Epoch 335/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0803 - acc: 0.9327     \n",
      "Epoch 336/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0813 - acc: 0.9343     \n",
      "Epoch 337/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0812 - acc: 0.9327     \n",
      "Epoch 338/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0781 - acc: 0.9377     \n",
      "Epoch 339/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0799 - acc: 0.9318     \n",
      "Epoch 340/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0796 - acc: 0.9327     \n",
      "Epoch 341/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0808 - acc: 0.9318     \n",
      "Epoch 342/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0807 - acc: 0.9343     \n",
      "Epoch 343/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203/1203 [==============================] - 1s - loss: 0.0776 - acc: 0.9327     \n",
      "Epoch 344/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0796 - acc: 0.9343     \n",
      "Epoch 345/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0763 - acc: 0.9418     \n",
      "Epoch 346/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0784 - acc: 0.9360     \n",
      "Epoch 347/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0783 - acc: 0.9360     \n",
      "Epoch 348/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0768 - acc: 0.9360     \n",
      "Epoch 349/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0779 - acc: 0.9343     \n",
      "Epoch 350/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0777 - acc: 0.9385     \n",
      "Epoch 351/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0772 - acc: 0.9360     \n",
      "Epoch 352/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0798 - acc: 0.9318     \n",
      "Epoch 353/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0810 - acc: 0.9318     \n",
      "Epoch 354/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0779 - acc: 0.9360     \n",
      "Epoch 355/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0782 - acc: 0.9352     \n",
      "Epoch 356/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0790 - acc: 0.9368     \n",
      "Epoch 357/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0806 - acc: 0.9310     \n",
      "Epoch 358/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0776 - acc: 0.9385     \n",
      "Epoch 359/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0778 - acc: 0.9352     \n",
      "Epoch 360/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0801 - acc: 0.9293     \n",
      "Epoch 361/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0788 - acc: 0.9318     \n",
      "Epoch 362/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0764 - acc: 0.9343     \n",
      "Epoch 363/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0765 - acc: 0.9377     \n",
      "Epoch 364/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0777 - acc: 0.9335     \n",
      "Epoch 365/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0787 - acc: 0.9327     \n",
      "Epoch 366/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0766 - acc: 0.9360     \n",
      "Epoch 367/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0778 - acc: 0.9352     \n",
      "Epoch 368/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0781 - acc: 0.9335     \n",
      "Epoch 369/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0757 - acc: 0.9393     \n",
      "Epoch 370/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0793 - acc: 0.9343     \n",
      "Epoch 371/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0779 - acc: 0.9343     \n",
      "Epoch 372/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0757 - acc: 0.9435     \n",
      "Epoch 373/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0785 - acc: 0.9310     \n",
      "Epoch 374/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0772 - acc: 0.9393     \n",
      "Epoch 375/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0766 - acc: 0.9368     \n",
      "Epoch 376/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0772 - acc: 0.9368     \n",
      "Epoch 377/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0764 - acc: 0.9368     \n",
      "Epoch 378/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0759 - acc: 0.9360     \n",
      "Epoch 379/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0769 - acc: 0.9352     \n",
      "Epoch 380/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0740 - acc: 0.9360     \n",
      "Epoch 381/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0776 - acc: 0.9335     \n",
      "Epoch 382/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0789 - acc: 0.9352     \n",
      "Epoch 383/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0754 - acc: 0.9393     \n",
      "Epoch 384/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0768 - acc: 0.9368     \n",
      "Epoch 385/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0758 - acc: 0.9401     \n",
      "Epoch 386/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0786 - acc: 0.9335     \n",
      "Epoch 387/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0745 - acc: 0.9410     \n",
      "Epoch 388/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0785 - acc: 0.9377     \n",
      "Epoch 389/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0780 - acc: 0.9310     \n",
      "Epoch 390/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0768 - acc: 0.9343     \n",
      "Epoch 391/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0756 - acc: 0.9385     \n",
      "Epoch 392/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0730 - acc: 0.9393     \n",
      "Epoch 393/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0748 - acc: 0.9352     \n",
      "Epoch 394/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0755 - acc: 0.9368     \n",
      "Epoch 395/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0777 - acc: 0.9327     \n",
      "Epoch 396/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0758 - acc: 0.9352     \n",
      "Epoch 397/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0777 - acc: 0.9343     \n",
      "Epoch 398/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0752 - acc: 0.9426     \n",
      "Epoch 399/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0745 - acc: 0.9368     \n",
      "Epoch 400/400\n",
      "1203/1203 [==============================] - 1s - loss: 0.0734 - acc: 0.9418     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff84996dd50>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "def get_callbacks(filepath, patience=8):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    \n",
    "    return [es, msave]\n",
    "\n",
    "callbacks = get_callbacks('./model.hdf5')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=400, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11848377342570453, 0.88778054877706891]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1203 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.069932156041921031, 0.94014962628198884]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = test_predictions.reshape((test_predictions.shape[0]))\n",
    "test_predictions = ['{:f}'.format(item) for item in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>0.007056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>0.953771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b20200e4</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>0.998649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a8d9b1fd</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29e7727e</td>\n",
       "      <td>0.000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92a51ffb</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c769ac97</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aee0547d</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id is_iceberg\n",
       "0  5941774d   0.007056\n",
       "1  4023181e   0.953771\n",
       "2  b20200e4   0.000156\n",
       "3  e7f018bb   0.999963\n",
       "4  4371c8c3   0.998649\n",
       "5  a8d9b1fd   0.999483\n",
       "6  29e7727e   0.000404\n",
       "7  92a51ffb   0.999998\n",
       "8  c769ac97   0.000000\n",
       "9  aee0547d   0.000000"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': test_predictions})\n",
    "submission.to_csv('first_sub.csv', index = False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=64\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 40)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            #Assert arrasy are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield X1i[0], X1i[1]\n",
    "\n",
    "# Finally create out generator\n",
    "gen_flow = gen_flow_for_two_inputs(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 [==============================] - 2s - loss: 0.2803 - acc: 0.7393 - val_loss: 0.2763 - val_acc: 0.7257\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 1s - loss: 0.2777 - acc: 0.7410 - val_loss: 0.2763 - val_acc: 0.7257\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 1s - loss: 0.3049 - acc: 0.7046 - val_loss: 0.2762 - val_acc: 0.7257\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 1s - loss: 0.2780 - acc: 0.7397 - val_loss: 0.2761 - val_acc: 0.7282\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 1s - loss: 0.2766 - acc: 0.7408 - val_loss: 0.2762 - val_acc: 0.7257\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 1s - loss: 0.2786 - acc: 0.7359 - val_loss: 0.2761 - val_acc: 0.7257\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 1s - loss: 0.2880 - acc: 0.7278 - val_loss: 0.2761 - val_acc: 0.7257\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 1s - loss: 0.2870 - acc: 0.7300 - val_loss: 0.2761 - val_acc: 0.7257\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 1s - loss: 0.2754 - acc: 0.7367 - val_loss: 0.2760 - val_acc: 0.7257\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 1s - loss: 0.2900 - acc: 0.7245 - val_loss: 0.2760 - val_acc: 0.7282\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 1s - loss: 0.2871 - acc: 0.7272 - val_loss: 0.2759 - val_acc: 0.7282\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 1s - loss: 0.2802 - acc: 0.7332 - val_loss: 0.2759 - val_acc: 0.7282\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 1s - loss: 0.2743 - acc: 0.7456 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 1s - loss: 0.2774 - acc: 0.7336 - val_loss: 0.2758 - val_acc: 0.7307\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 1s - loss: 0.2803 - acc: 0.7326 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 1s - loss: 0.2867 - acc: 0.7274 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 1s - loss: 0.2843 - acc: 0.7356 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 1s - loss: 0.2884 - acc: 0.7211 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 1s - loss: 0.2800 - acc: 0.7348 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 1s - loss: 0.2890 - acc: 0.7195 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 1s - loss: 0.2795 - acc: 0.7309 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 1s - loss: 0.2818 - acc: 0.7336 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 1s - loss: 0.2847 - acc: 0.7311 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 1s - loss: 0.2833 - acc: 0.7306 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 1s - loss: 0.2788 - acc: 0.7310 - val_loss: 0.2758 - val_acc: 0.7282\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 1s - loss: 0.2730 - acc: 0.7534 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 1s - loss: 0.2902 - acc: 0.7211 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 1s - loss: 0.2858 - acc: 0.7318 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 1s - loss: 0.2794 - acc: 0.7328 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 1s - loss: 0.2867 - acc: 0.7310 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 1s - loss: 0.2809 - acc: 0.7365 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 1s - loss: 0.2863 - acc: 0.7254 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 1s - loss: 0.2820 - acc: 0.7321 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 1s - loss: 0.2858 - acc: 0.7352 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 1s - loss: 0.2743 - acc: 0.7334 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 1s - loss: 0.2831 - acc: 0.7307 - val_loss: 0.2757 - val_acc: 0.7282\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 1s - loss: 0.2738 - acc: 0.7393 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 1s - loss: 0.2956 - acc: 0.7150 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 1s - loss: 0.2792 - acc: 0.7348 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 1s - loss: 0.2713 - acc: 0.7438 - val_loss: 0.2757 - val_acc: 0.7307\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 1s - loss: 0.2728 - acc: 0.7497 - val_loss: 0.2757 - val_acc: 0.7307\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 1s - loss: 0.2949 - acc: 0.7187 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 1s - loss: 0.2712 - acc: 0.7454 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 1s - loss: 0.2959 - acc: 0.7167 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 1s - loss: 0.2827 - acc: 0.7309 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 1s - loss: 0.2781 - acc: 0.7372 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 1s - loss: 0.2801 - acc: 0.7322 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 1s - loss: 0.2899 - acc: 0.7237 - val_loss: 0.2756 - val_acc: 0.7282\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 1s - loss: 0.2784 - acc: 0.7389 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 1s - loss: 0.2837 - acc: 0.7326 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 1s - loss: 0.2776 - acc: 0.7322 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 1s - loss: 0.2814 - acc: 0.7321 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 1s - loss: 0.2870 - acc: 0.7257 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 1s - loss: 0.2762 - acc: 0.7404 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 1s - loss: 0.2889 - acc: 0.7209 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 1s - loss: 0.2742 - acc: 0.7356 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 1s - loss: 0.2882 - acc: 0.7269 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 1s - loss: 0.2795 - acc: 0.7359 - val_loss: 0.2756 - val_acc: 0.7307\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 1s - loss: 0.2876 - acc: 0.7272 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 1s - loss: 0.2798 - acc: 0.7385 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 1s - loss: 0.2966 - acc: 0.7176 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 1s - loss: 0.2819 - acc: 0.7359 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 1s - loss: 0.2691 - acc: 0.7407 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 1s - loss: 0.2862 - acc: 0.7257 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 1s - loss: 0.2828 - acc: 0.7334 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 1s - loss: 0.2713 - acc: 0.7465 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s - loss: 0.2970 - acc: 0.7174 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 1s - loss: 0.2764 - acc: 0.7376 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 1s - loss: 0.2954 - acc: 0.7115 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 1s - loss: 0.2835 - acc: 0.7237 - val_loss: 0.2755 - val_acc: 0.7307\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 1s - loss: 0.2774 - acc: 0.7454 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 1s - loss: 0.2780 - acc: 0.7396 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 1s - loss: 0.2848 - acc: 0.7293 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 1s - loss: 0.2709 - acc: 0.7441 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 1s - loss: 0.2875 - acc: 0.7226 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 1s - loss: 0.2838 - acc: 0.7256 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 1s - loss: 0.2835 - acc: 0.7339 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 1s - loss: 0.2836 - acc: 0.7252 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 1s - loss: 0.2616 - acc: 0.7547 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 1s - loss: 0.2941 - acc: 0.7191 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 1s - loss: 0.2663 - acc: 0.7501 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 1s - loss: 0.2934 - acc: 0.7202 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 1s - loss: 0.2707 - acc: 0.7376 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 1s - loss: 0.2840 - acc: 0.7270 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 1s - loss: 0.2824 - acc: 0.7317 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 1s - loss: 0.2892 - acc: 0.7263 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 1s - loss: 0.2714 - acc: 0.7458 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 1s - loss: 0.2807 - acc: 0.7330 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 1s - loss: 0.2783 - acc: 0.7360 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 1s - loss: 0.2793 - acc: 0.7346 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 1s - loss: 0.2839 - acc: 0.7387 - val_loss: 0.2754 - val_acc: 0.7282\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 1s - loss: 0.2814 - acc: 0.7336 - val_loss: 0.2754 - val_acc: 0.7282\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 1s - loss: 0.2730 - acc: 0.7419 - val_loss: 0.2754 - val_acc: 0.7282\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 1s - loss: 0.2842 - acc: 0.7332 - val_loss: 0.2754 - val_acc: 0.7282\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 1s - loss: 0.2921 - acc: 0.7315 - val_loss: 0.2754 - val_acc: 0.7282\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 1s - loss: 0.2700 - acc: 0.7432 - val_loss: 0.2754 - val_acc: 0.7282\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 1s - loss: 0.2766 - acc: 0.7369 - val_loss: 0.2754 - val_acc: 0.7282\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 1s - loss: 0.2855 - acc: 0.7239 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 1s - loss: 0.2831 - acc: 0.7332 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 1s - loss: 0.2685 - acc: 0.7528 - val_loss: 0.2754 - val_acc: 0.7307\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 1s - loss: 0.2740 - acc: 0.7393 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 1s - loss: 0.2848 - acc: 0.7328 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 1s - loss: 0.2950 - acc: 0.7170 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 1s - loss: 0.2718 - acc: 0.7445 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 1s - loss: 0.2757 - acc: 0.7413 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 1s - loss: 0.2708 - acc: 0.7463 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 1s - loss: 0.2863 - acc: 0.7228 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 1s - loss: 0.2837 - acc: 0.7343 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 1s - loss: 0.2853 - acc: 0.7289 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 1s - loss: 0.2829 - acc: 0.7326 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 1s - loss: 0.2780 - acc: 0.7377 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 1s - loss: 0.2786 - acc: 0.7315 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 1s - loss: 0.2818 - acc: 0.7393 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 1s - loss: 0.2770 - acc: 0.7333 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 1s - loss: 0.2768 - acc: 0.7384 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 1s - loss: 0.2901 - acc: 0.7224 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 1s - loss: 0.2861 - acc: 0.7324 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 1s - loss: 0.2836 - acc: 0.7341 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 1s - loss: 0.2768 - acc: 0.7400 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 1s - loss: 0.2787 - acc: 0.7321 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 1s - loss: 0.2859 - acc: 0.7304 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 1s - loss: 0.2871 - acc: 0.7267 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 1s - loss: 0.2712 - acc: 0.7441 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 1s - loss: 0.2806 - acc: 0.7350 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 1s - loss: 0.2849 - acc: 0.7322 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 1s - loss: 0.2751 - acc: 0.7387 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 1s - loss: 0.2724 - acc: 0.7404 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 1s - loss: 0.2830 - acc: 0.7333 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 1s - loss: 0.2757 - acc: 0.7405 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 1s - loss: 0.2835 - acc: 0.7330 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 1s - loss: 0.2687 - acc: 0.7421 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 1s - loss: 0.2875 - acc: 0.7296 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 133/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s - loss: 0.2851 - acc: 0.7311 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 1s - loss: 0.2917 - acc: 0.7228 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 1s - loss: 0.2755 - acc: 0.7415 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 1s - loss: 0.2798 - acc: 0.7336 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 1s - loss: 0.2869 - acc: 0.7250 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 1s - loss: 0.2714 - acc: 0.7484 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 1s - loss: 0.2875 - acc: 0.7252 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 1s - loss: 0.2829 - acc: 0.7372 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 1s - loss: 0.2739 - acc: 0.7426 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 1s - loss: 0.2719 - acc: 0.7432 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 1s - loss: 0.2922 - acc: 0.7178 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 1s - loss: 0.2871 - acc: 0.7261 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 1s - loss: 0.2769 - acc: 0.7345 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 1s - loss: 0.2855 - acc: 0.7221 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 1s - loss: 0.2788 - acc: 0.7380 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 1s - loss: 0.2790 - acc: 0.7370 - val_loss: 0.2753 - val_acc: 0.7307\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 1s - loss: 0.2758 - acc: 0.7386 - val_loss: 0.2752 - val_acc: 0.7307\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 1s - loss: 0.2840 - acc: 0.7321 - val_loss: 0.2752 - val_acc: 0.7307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff84ad5c0d0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit_generator(gen_flow, validation_data=(X_valid, y_valid),\n",
    "                    steps_per_epoch=len(X_train) / batch_size, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
